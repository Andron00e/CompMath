{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeXTSdSfKdL2"
      },
      "source": [
        "## *Задача 1.  Генератор матриц* \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19smb2owQS40"
      },
      "source": [
        "Реализовать генератор матрциц, который должен поддерживать функции:\n",
        "* Генерация абсолютно случайной матрицы $n\\times m$\n",
        "* Генерация случайной диагональной матрицы $n\\times n$\n",
        "* Генерация случайной верхнетреугольной матрицы\n",
        "* Генерация случайной нижнетреугольной матрицы\n",
        "* Генерация симметричной матрицы\n",
        "* Генерация вырожденной матрицы\n",
        "* Генерация матрицы ступенчатого вида $n\\times n$ ранга $m$\n",
        "* Генерация возмущения матрицы $n\\times m$, каждый элемент которой не превосходит по модулю заданный $\\varepsilon$\n",
        "\n",
        "Оценить вероятность того, что созданная матрица будет вырожденной. (Комментарий от Грязева – только для квадратной случайной матрицы)\n",
        "\n",
        "Оценить величину нормы матрицы возмущений в зависимости от параметра $\\varepsilon$ (оценить верхную границу).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def random_matrix (n, m):\n",
        "  return np.random.rand(n, m)\n",
        "print(random_matrix(4, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkztgAJuwDjC",
        "outputId": "33a7a506-4037-4110-c5f1-4579a4cb544e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.82012466 0.46954132 0.38566546]\n",
            " [0.66967897 0.14933353 0.28867283]\n",
            " [0.00294817 0.23543852 0.95360983]\n",
            " [0.98743743 0.82718157 0.89983209]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def diag_matrix(n):\n",
        "  return np.diag(np.random.rand(n))\n",
        "print(diag_matrix(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1cQKsByBWme",
        "outputId": "83f5e276-e645-45d4-9c1a-45867c152503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5977295  0.         0.         0.         0.        ]\n",
            " [0.         0.5125699  0.         0.         0.        ]\n",
            " [0.         0.         0.24438563 0.         0.        ]\n",
            " [0.         0.         0.         0.02127106 0.        ]\n",
            " [0.         0.         0.         0.         0.17762556]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upper_triangular(n):\n",
        "  return np.triu(np.random.rand(n, n))\n",
        "print(upper_triangular(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmdW6wvSBugK",
        "outputId": "4b9dbb7c-1f28-49e8-a410-9be05b0221bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9054841  0.11911499 0.28050092 0.596633   0.136617  ]\n",
            " [0.         0.06884995 0.03931739 0.24335036 0.56630098]\n",
            " [0.         0.         0.73447049 0.15416079 0.84184971]\n",
            " [0.         0.         0.         0.83790855 0.065538  ]\n",
            " [0.         0.         0.         0.         0.67038474]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lower_triangular(n):\n",
        "  return np.tril(np.random.rand(n, n))\n",
        "print(lower_triangular(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWhxdmpXCtJk",
        "outputId": "17097d5c-69ef-4215-c650-5b8b6dbe122d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.75159742 0.         0.         0.         0.        ]\n",
            " [0.68996213 0.36339963 0.         0.         0.        ]\n",
            " [0.1932113  0.96619638 0.24793717 0.         0.        ]\n",
            " [0.8281344  0.37486633 0.36124329 0.72705174 0.        ]\n",
            " [0.82824851 0.52212792 0.25518613 0.48008046 0.52567325]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def symm_matrix(n):\n",
        "  M = random_matrix(n, n)\n",
        "  return (M + M.T)\n",
        "print(symm_matrix(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnGud3HKDCXt",
        "outputId": "69b4a933-be2b-4c8a-913f-e65c0d00661e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.40659241 1.69209903 1.44977444 1.06366824 0.98591231]\n",
            " [1.69209903 1.84546817 0.77743408 0.31429359 0.29286513]\n",
            " [1.44977444 0.77743408 0.58360169 1.03182319 0.65885455]\n",
            " [1.06366824 0.31429359 1.03182319 1.22056138 0.2894059 ]\n",
            " [0.98591231 0.29286513 0.65885455 0.2894059  1.36496586]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def singular_matrix(n):\n",
        "    if n == 1:\n",
        "      return np.array([[0]])\n",
        "    M = random_matrix(n,n)\n",
        "    M[1] = M[0]\n",
        "    return M\n",
        "print(singular_matrix(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gICqiRFFEFCl",
        "outputId": "ae8ef892-4fa5-4553-b3a1-753b9fb616be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.61385967 0.28926386 0.65485748 0.37440383 0.76092968]\n",
            " [0.61385967 0.28926386 0.65485748 0.37440383 0.76092968]\n",
            " [0.43476102 0.41636139 0.69046785 0.89663359 0.85799066]\n",
            " [0.28653635 0.36267986 0.44350195 0.18117766 0.9708724 ]\n",
            " [0.04792886 0.90822317 0.61047796 0.91036496 0.14365437]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stairs_matrix(n, m):\n",
        "  M = upper_triangular(n)\n",
        "  M[m:] = 0\n",
        "  return M\n",
        "print(stairs_matrix(5, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhb22dwsGyTA",
        "outputId": "99081ce4-22ec-480c-df00-8967d957176a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.62449287 0.73998965 0.38310651 0.5401539  0.85930796]\n",
            " [0.         0.65645054 0.28544183 0.13709169 0.96982579]\n",
            " [0.         0.         0.49902542 0.48317011 0.61135711]\n",
            " [0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def noisy_matrix(n, m, epsilon):\n",
        "  return np.random.uniform(-epsilon, epsilon, size=[n, m])\n",
        "print(noisy_matrix(5, 4, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWaPf320HzKT",
        "outputId": "8fbff44d-a4ba-408f-e06d-f8f61e799f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.10727545 -0.61004514 -0.13950333 -0.37563459]\n",
            " [-0.08756269 -0.87729351  0.47919857 -0.46936753]\n",
            " [-0.57886475  0.96432417  0.21817247 -0.34223291]\n",
            " [ 0.70306319  0.05742253  0.96895267  0.37993644]\n",
            " [ 0.25683632 -0.51798433  0.53097496  0.73271099]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "||A||_F=\\sqrt{\\sum_{i=1}^{n}\\sum_{j=1}^{n}|a_{ij}|^2} \\leq \\sqrt{n^2|\\varepsilon|^2} \\leq n|\\varepsilon|\n",
        "$$"
      ],
      "metadata": {
        "id": "EyyCiJ9XJhSw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS3EHa1aKmJi"
      },
      "source": [
        "#Задача 2. Эквивалентность первых двух норм.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMUUtmljQZO1"
      },
      "source": [
        "Найдите константы $C_1$  и  $C_2$ такие, что\n",
        "\n",
        "$\\ C_1||\\mathbf{x}||_2\\leq||\\mathbf{x}||_1\\leq C_2||\\mathbf{x}||_2$ \n",
        "\n",
        "\n",
        "Указание: в качестве подсказки можно использовать визуализацию норм из документа с теорией. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\frac{\\sum |x_i|}{n} \\le \\sqrt{\\frac{\\sum |x_i|^2}{n}} \\Rightarrow ||x||_1 \\le \\sqrt{n} ||x||_2\n",
        "$$\n",
        "\n",
        "$$\n",
        "C_1 = 1\n",
        "$$\n",
        "Итого:\n",
        "$$\n",
        "C_1 = 1,\\,\\, C_2 = \\sqrt{n}\n",
        "$$"
      ],
      "metadata": {
        "id": "koYnrGSdKWML"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpR6GBRtKmXq"
      },
      "source": [
        "#Задача 3.  Евклидова и бесконечная норма."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ7BfspuTsOt"
      },
      "source": [
        " Пусть x — вектор размерности m, а A — матрица m×n. Докажите следующие неравенства и приведите\n",
        "примеры таких x и A, при которых неравенства обращаются в равенства: \n",
        "\n",
        "- $\\|x\\|_2 \\leq \\sqrt{m}\\|x\\|_{\\infty}$\n",
        "- $\\|A\\|_{\\infty} \\leq \\sqrt{n}\\|A\\|_2$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)\n",
        "$$\n",
        "||x||_2 = \\le \\sqrt{\\sum_{i=1}^m \\max_{1 \\le i\\le m}|x_i|^2} = \\sqrt{\\sum_{i=1}^m \\|x\\|^2_\\infty} = \\sqrt{m}\\|x\\|_\\infty\n",
        "$$\n",
        "2)\n",
        "$$\n",
        "||A||_\\infty  :=\\sup \\frac{\\|Ax\\|_\\infty}{\\|x\\|_\\infty} \\leq \\sup \\frac{\\|Ax\\|_2}{\\frac{\\|x\\|_2}{\\sqrt{n}}} = \\sqrt{n}\\|A\\|_2\n",
        "$$"
      ],
      "metadata": {
        "id": "N3jPJW3nMHob"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-476ZEtKmk5"
      },
      "source": [
        "#Задача 4. Норма Фробениуса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzG3RPf-T07c"
      },
      "source": [
        "Докажите, что для любой унитарной матрицы U (и для произвольной матрицы A) имеет место равенство\n",
        "\n",
        " $∥UA∥_F = ∥AU∥_F = ∥A∥_F$ , \n",
        " \n",
        " где $∥ ∥_F$ — норма Фробениуса.\n",
        "\n",
        "Указание.  \n",
        "Задачу можно решить без вычислений, если использовать геометрический смысл нормы Фробениуса и геометрические свойства умножения на унитарную матрицу (что при умножении на неё сохраняется). "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "||A||_F = \\sqrt{\\mathrm{tr}(AA^*)} = \\sqrt{\\mathrm{tr}(AUU^* A^*)} = \\sqrt{\\mathrm{tr}(AU (AU)^*)} = ||AU||_F\n",
        "$$\n",
        "\n",
        "$$\n",
        "||A||_F = \\sqrt{\\mathrm{tr}(A^* A)} = \\sqrt{\\mathrm{tr}(A^* U^* U A)} = \\sqrt{\\mathrm{tr}((UA)^* UA)} = ||UA||_F\n",
        "$$"
      ],
      "metadata": {
        "id": "tAq-N_PjNB_6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8jGlqhJKmpB"
      },
      "source": [
        "#Задача 5. Тензорная свёртка. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smdRrcYuT4he"
      },
      "source": [
        "Рассмотрим функцию, отображающую шесть тензоров на один тензор: $Z\\left(\\lambda^{(1)}, \\lambda^{(2)}, \\lambda^{(3)}, \\Gamma^{(1)}, \\Gamma^{(2)}, U\\right)$ :\n",
        "\n",
        "\n",
        "$$\n",
        "Z_{a h i j}=\\sum_{b c d e f g} \\lambda^{(1)}{ }_{a b} \\Gamma_{c b d}^{(1)} \\lambda^{(2)}{ }_{d e} \\Gamma_{f e g}^{(2)} \\lambda_{g h}^{(3)} U_{i j c f}\n",
        "$$ \n",
        "\n",
        "редположив, что все индексы пробегают значения от 1 до χ, проведите эксперимент и сравните скорость\n",
        "различных реализаций функции Z. Исследуйте значения χ в диапазоне 3–50. \n",
        "\n",
        "\n",
        "- В файле convolution. ipynb вы можете найти релизацию глупого способа вычисления этой свертки, который требует $\\chi^4 \\times \\chi^6=\\chi^{10}$ операций. На самом деле это можно вычислить гораздо быстрее!\n",
        "- С помощью функции numpy . einsum (нужно использовать аргумент optimize), можно добиться намного большей производительности. Чтобы понять, что происходит под капотом, воспользуйтесь функцией numpy.einsum_path. Какое минимальное количество операций требуется для вычисления $Z$ ?\n",
        "- Посмотрев на вывод функции numpy.einsum_path, peализуйте алгоритм для вычисления $Z$, который столь же эффективен, как numpy.einsum, но использует более элементарные numpy.dot и numpy.tensor_dot."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOfqD7X1Odr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "634QUTkyKnWR"
      },
      "source": [
        "#Задача 6.  k-means clustering. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gHzjikte83x"
      },
      "source": [
        "Выбор метрики (нормы разницы между любыми двумя векторами, или функции расстояния между любой парой точек) очень важен для многих алгоритмов машинного обучения. Рассмотрим на примере задачи кластеризации. \n",
        "\n",
        "Кластеризация — это разделение множества входных векторов на группы (кластеры) по степени «схожести» друг с другом.\n",
        "\n",
        "Кластеризация в Data Mining приобретает ценность тогда, когда она выступает одним из этапов анализа данных, построения законченного аналитического решения. Аналитику часто легче выделить группы схожих объектов, изучить их особенности и построить для каждой группы отдельную модель, чем создавать одну общую модель для всех данных. Таким приемом постоянно пользуются в маркетинге, выделяя группы клиентов, покупателей, товаров и разрабатывая для каждой из них отдельную стратегию.\n",
        "\n",
        "\n",
        "Евклидова метрика \n",
        "\n",
        "\n",
        "— наиболее распространенная. Она является геометрическим расстоянием в многомерном пространстве.\n",
        "\n",
        "\n",
        "Квадрат евклидовой метрики. \n",
        "\n",
        "\n",
        "Иногда может возникнуть желание возвести в квадрат стандартное евклидово расстояние, чтобы придать большие веса более отдаленным друг от друга объектам.\n",
        "\n",
        "\n",
        "Метрика городских кварталов (манхэттенская). \n",
        "\n",
        "\n",
        "Это расстояние является суммой модулей разностей координат. В большинстве случаев эта метрика приводит к таким же результатам, как и для обычного расстояния Евклида. Однако отметим, что для этой меры влияние отдельных больших разностей (выбросов) уменьшается (так как они не возводятся в квадрат).\n",
        "\n",
        "Расстояние Чебышева. \n",
        "\n",
        "Это метрика шахматной доски (Расстоянием Чебышёва между n-мерными числовыми векторами называется максимум модуля разности компонент этих векторов). Это расстояние может оказаться полезным, когда желают определить два объекта как «различные», если они различаются по какой-либо одной координате (каким-либо одним измерением).\n",
        "\n",
        "Расстояние Чебышёва называют также метрикой Чебышёва, равномерной метрикой, sup-метрикой и бокс-метрикой; также иногда она называется метрикой решётки, метрикой шахматной доски, метрикой хода короля и 8-метрикой.\n",
        "\n",
        "Степенная метрика. \n",
        "\n",
        "Иногда желают прогрессивно увеличить или уменьшить вес, относящийся к размерности, для которой соответствующие объекты сильно отличаются. Это может быть достигнуто с использованием степенного расстояния.\n",
        "\n",
        "\n",
        "Выбор метрики (критерия схожести) лежит полностью на исследователе. При выборе различных мер результаты кластеризации могут существенно отличаться.\n",
        "\n",
        "Алгоритм k-means (k-средних)\n",
        "\n",
        "Наиболее простой, но в то же время достаточно неточный метод кластеризации в классической реализации. Он разбивает множество элементов векторного пространства на заранее известное число кластеров k. Действие алгоритма таково, что он стремится минимизировать среднеквадратичное отклонение на точках каждого кластера. Основная идея заключается в том, что на каждой итерации перевычисляется центр масс для каждого кластера, полученного на предыдущем шаге, затем векторы разбиваются на кластеры вновь в соответствии с тем, какой из новых центров оказался ближе по выбранной метрике. Алгоритм завершается, когда на какой-то итерации не происходит изменения кластеров.\n",
        "\n",
        "Проблемы алгоритма k-means:\n",
        "* необходимо заранее знать количество кластеров. Мной было предложено метод определения количества кластеров, который основывался на нахождении кластеров, распределенных по некоему закону (в моем случае все сводилось к нормальному закону). После этого выполнялся классический алгоритм k-means, который давал более точные результаты.\n",
        "* алгоритм очень чувствителен к выбору начальных центров кластеров. Классический вариант подразумевает случайный выбор класторов, что очень часто являлось источником погрешности. Как вариант решения, необходимо проводить исследования объекта для более точного определения центров начальных кластеров. В моем случае на начальном этапе предлагается принимать в качестве центов самые отдаленные точки кластеров.\n",
        "* не справляется с задачей, когда объект принадлежит к разным кластерам в равной степени или не принадлежит ни одному.\n",
        "\n",
        "\n",
        "В блокноте kmeans.ipynb вы можете найти наивную реализацию.\n",
        "Изучите код, убедитесь, что вы его поняли. Вы найдете там две функции dist_i и dist_ij, которые\n",
        "(намеренно) реализованы довольно неэффективно. Улучшите их, избавившись от циклов с помощью век-\n",
        "торизации из numpy, и измерьте ускорение алгоритма в целом при N = 10000.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$комментарий\\,к\\,6\\,задаче\\\\\n",
        "центр масс O(N*dim)\\\\\n",
        "расстояния O(N*k*dim)\\\\\n",
        "поиск минимума O(N*K)$"
      ],
      "metadata": {
        "id": "VBJnnjeU1zCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Дополнительное задание. Нечеткий алгоритм кластеризации с-means.\n"
      ],
      "metadata": {
        "id": "gKnAIng1T-Ex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С последней проблемой k-means успешно справляется алгоритм с-means. Вместо однозначного ответа на вопрос к какому кластеру относится объект, он определяет вероятность того, что объект принадлежит к тому или иному кластеру. Таким образом, утверждение «объект А принадлежит к кластеру 1 с вероятностью 90%, к кластеру 2 — 10% » верно и более удобно.\n",
        "\n",
        "Остальные проблемы у с-means такие же, как у k-means, но они нивелируются благодаря нечеткости разбиения.\n",
        "\n",
        "Метод нечеткой кластеризации C-средних имеет ограниченное применение из-за существенного недостатка — невозможность корректного разбиения на кластеры, в случае когда кластеры имеют различную дисперсию по различным размерностям (осям) элементов (например, кластер имеет форму эллипса). Данный недостаток устранен в алгоритмах Mixture models и GMM (Gaussian mixture models). \n",
        "\n",
        "\n",
        "Документация методов кластеризации для sklearn есть здесь https://scikit-learn.org/stable/modules/clustering.html#k-means . \n",
        "\n",
        "\n",
        "\n",
        "Используя библиотеку scikit-learn, реализуйте Gaussian mixture models и обычный k-means.  Подберите такой набор данных, на котором первый метод справляется хорошо, а второй метод даёт плохие результаты, и продемонстрируйте это. Сделайте это для нескольких разных метрик и сравните результаты между собой.\n",
        "\n",
        "https://scikit-learn.ru/example/  примеры подобного.\n",
        "\n",
        "https://neurohive.io/ru/osnovy-data-science/vvedenie-v-scikit-learn/  введение в sklearn. На этом сайте много полезных статей и ссылок на курсы. "
      ],
      "metadata": {
        "id": "umU-jwFAT7nj"
      }
    }
  ]
}